{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.data_path= 'data'\n",
    "        self.dataset= 'masked_pwc'\n",
    "        self.batch_size= 32\n",
    "        self.model= 'unet1d'\n",
    "        self.lr= 0.001\n",
    "        self.num_epochs= 100\n",
    "        self.n_data = 10000\n",
    "        self.min_sep = 5\n",
    "        self.valid_interval= 1\n",
    "        self.save_interval= 1\n",
    "        self.seed = 0\n",
    "        self.output_dir= 'experiments'\n",
    "        self.experiment= None\n",
    "        self.resume_training= False\n",
    "        self.restore_file= None\n",
    "        self.no_save= False\n",
    "        self.step_checkpoints= False\n",
    "        self.no_log= False\n",
    "        self.log_interval= 100\n",
    "        self.no_visual= False\n",
    "        self.visual_interval= 100\n",
    "        self.no_progress= False\n",
    "        self.draft= False\n",
    "        self.dry_run= False\n",
    "        self.in_channels= 1\n",
    "        self.bias= False\n",
    "        self.test_num = 0\n",
    "        # UNET\n",
    "        self.residual = False\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-22 12:54:25] COMMAND: /home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py -f /home/michael/.local/share/jupyter/runtime/kernel-f91a71ae-bcbf-48ff-995c-30db5472d1c6.json\n",
      "[2020-09-22 12:54:25] Arguments: {'data_path': 'data', 'dataset': 'masked_pwc', 'batch_size': 32, 'model': 'unet1d', 'lr': 0.001, 'num_epochs': 100, 'n_data': 10000, 'min_sep': 5, 'valid_interval': 1, 'save_interval': 1, 'seed': 0, 'output_dir': 'experiments', 'experiment': 'unet1d-Sep-22-12:54:25', 'resume_training': False, 'restore_file': None, 'no_save': False, 'step_checkpoints': False, 'no_log': False, 'log_interval': 100, 'no_visual': False, 'visual_interval': 100, 'no_progress': False, 'draft': False, 'dry_run': False, 'in_channels': 1, 'bias': False, 'test_num': 0, 'residual': False, 'experiment_dir': 'experiments/unet1d/unet1d-Sep-22-12:54:25', 'checkpoint_dir': 'experiments/unet1d/unet1d-Sep-22-12:54:25/checkpoints', 'log_dir': 'experiments/unet1d/unet1d-Sep-22-12:54:25/logs', 'log_file': 'experiments/unet1d/unet1d-Sep-22-12:54:25/logs/train.log'}\n"
     ]
    }
   ],
   "source": [
    "# gpu or cpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "utils.setup_experiment(args)\n",
    "utils.init_logging(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-09-22 12:54:37] Built a model consisting of 72,000 parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv1): PartialConv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      "  (conv2): PartialConv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv3): PartialConv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "  (conv4): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv5): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)\n",
      "  (conv6): PartialConv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), bias=False)\n",
      "  (conv7): ConvTranspose1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,), bias=False)\n",
      "  (conv8): PartialConv1d(96, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "  (conv9): PartialConv1d(32, 1, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "# torch.save(model.state_dict(), MODEL_PATH)\n",
    "# MODEL_PATH = \"models/trained/dncnn1d_partialconv_5kdata_20epoch_08_12_20.pth\"\n",
    "MODEL_PATH = \"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"\n",
    "\n",
    "train_new_model = True\n",
    "\n",
    "\n",
    "\n",
    "# Build data loaders, a model and an optimizer\n",
    "if train_new_model:\n",
    "    model = models.build_model(args).to(device)\n",
    "else:\n",
    "    model = models.build_model(args)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 60, 70, 80, 90, 100], gamma=0.5)\n",
    "logging.info(f\"Built a model consisting of {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "if args.resume_training:\n",
    "    state_dict = utils.load_checkpoint(args, model, optimizer, scheduler)\n",
    "    global_step = state_dict['last_step']\n",
    "    start_epoch = int(state_dict['last_step']/(403200/state_dict['args'].batch_size))+1\n",
    "else:\n",
    "    global_step = -1\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_dataset is a function in utils/data/__init__.py\n",
    "train_loader, valid_loader, _ = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.batch_size,\n",
    "                                                   min_sep = args.min_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track moving average of loss values\n",
    "train_meters = {name: utils.RunningAverageMeter(0.98) for name in ([\"train_loss\", \"train_psnr\", \"train_ssim\"])}\n",
    "valid_meters = {name: utils.AverageMeter() for name in ([\"valid_psnr\", \"valid_ssim\"])}\n",
    "writer = SummaryWriter(log_dir=args.experiment_dir) if not args.no_visual else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 00:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape before conv3:  torch.Size([32, 32, 64])\n",
      "out shape before conv3:  torch.Size([32, 32, 64])\n",
      "mask shape before conv4:  torch.Size([32, 64, 32])\n",
      "out shape before conv4:  torch.Size([32, 64, 32])\n",
      "mask shape before conv5:  torch.Size([32, 64, 32])\n",
      "out shape before conv5:  torch.Size([32, 64, 32])\n",
      "mask shape before conv6:  torch.Size([32, 64, 32])\n",
      "out shape before conv6:  torch.Size([32, 64, 32])\n",
      "mask shape before conv7:  torch.Size([32, 64, 32])\n",
      "out shape before conv7:  torch.Size([32, 64, 32])\n",
      "mask shape before conv8:  torch.Size([32, 64, 64])\n",
      "out shape before conv8:  torch.Size([32, 96, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 96, 3], expected input[32, 64, 64] to have 96 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3216f6860e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmask_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# only use the mask part of the outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mraw_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmask_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mraw_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask_inputs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-virtual-environments/data/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bfcnn/bias_free_denoising/models/unet1d_partialconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask_in)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mask shape before conv8: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out shape before conv8: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mprelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mprelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python-virtual-environments/data/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bfcnn/bias_free_denoising/models/PartialConv1d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, mask_in)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# print(\"padding: \",self.padding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m# print(\"dilation: \",self.dilation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_maskUpdater\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# for mixed precision training, change 1e-8 to 1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 96, 3], expected input[32, 64, 64] to have 96 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    if args.resume_training:\n",
    "        if epoch %10 == 0:\n",
    "            optimizer.param_groups[0][\"lr\"] /= 2\n",
    "            print('learning rate reduced by factor of 2')\n",
    "\n",
    "    train_bar = utils.ProgressBar(train_loader, epoch)\n",
    "    for meter in train_meters.values():\n",
    "        meter.reset()\n",
    "\n",
    "    for batch_id, (clean, mask) in enumerate(train_bar):\n",
    "        # dataloader returns [clean, mask] list\n",
    "        model.train()\n",
    "        global_step += 1\n",
    "        inputs = clean.to(device)\n",
    "        mask_inputs = mask.to(device)\n",
    "        # only use the mask part of the outputs\n",
    "        raw_outputs = model(inputs,mask_inputs)\n",
    "        outputs = (1-mask_inputs)*raw_outputs + mask_inputs*inputs\n",
    "        \n",
    "        # TO DO, only run loss on masked part of output\n",
    "        loss = F.mse_loss(outputs, inputs, reduction=\"sum\") / (inputs.size(0) * 2)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_psnr = utils.psnr(outputs, inputs)\n",
    "        train_ssim = utils.ssim(outputs, inputs)\n",
    "        train_meters[\"train_loss\"].update(loss.item())\n",
    "        train_meters[\"train_psnr\"].update(train_psnr.item())\n",
    "        train_meters[\"train_ssim\"].update(train_ssim.item())\n",
    "        train_bar.log(dict(**train_meters, lr=optimizer.param_groups[0][\"lr\"]), verbose=True)\n",
    "\n",
    "        if writer is not None and global_step % args.log_interval == 0:\n",
    "            writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], global_step)\n",
    "            writer.add_scalar(\"loss/train\", loss.item(), global_step)\n",
    "            writer.add_scalar(\"psnr/train\", train_psnr.item(), global_step)\n",
    "            writer.add_scalar(\"ssim/train\", train_ssim.item(), global_step)\n",
    "            gradients = torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None], dim=0)\n",
    "            writer.add_histogram(\"gradients\", gradients, global_step)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    if epoch % args.valid_interval == 0:\n",
    "        model.eval()\n",
    "        for meter in valid_meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "        valid_bar = utils.ProgressBar(valid_loader)\n",
    "        \n",
    "        for sample_id, (clean, mask) in enumerate(valid_bar):\n",
    "            with torch.no_grad():\n",
    "                inputs = clean.to(device)\n",
    "                mask_inputs = mask.to(device)\n",
    "                # only use the mask part of the outputs\n",
    "                raw_output = model(inputs,mask_inputs)\n",
    "                output = (1-mask_inputs)*raw_output + mask_inputs*inputs\n",
    "#                 output = model(inputs)\n",
    "#                 sample = noisy_clean_sample[1].to(device)\n",
    "#                 noisy_inputs = noisy_clean_sample[0].to(device);\n",
    "#                 output = model(noisy_inputs)\n",
    "\n",
    "                valid_psnr = utils.psnr(inputs, output)\n",
    "                valid_meters[\"valid_psnr\"].update(valid_psnr.item())\n",
    "                valid_ssim = utils.ssim(inputs, output)\n",
    "                valid_meters[\"valid_ssim\"].update(valid_ssim.item())\n",
    "\n",
    "                ### Uncomment these when finished\n",
    "                if writer is not None and sample_id < 10:\n",
    "                    image = torch.cat([inputs, torch.mul(inputs, mask_inputs), output], dim=0)\n",
    "                    image = torchvision.utils.make_grid(image.clamp(0, 1), nrow=3, normalize=False)\n",
    "                    writer.add_image(f\"valid_samples/{sample_id}\", image, global_step)\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"psnr/valid\", valid_meters['valid_psnr'].avg, global_step)\n",
    "            writer.add_scalar(\"ssim/valid\", valid_meters['valid_ssim'].avg, global_step)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        logging.info(train_bar.print(dict(**train_meters, **valid_meters, lr=optimizer.param_groups[0][\"lr\"])))\n",
    "        utils.save_checkpoint(args, global_step, model, optimizer, score=valid_meters[\"valid_psnr\"].avg, mode=\"max\")\n",
    "    scheduler.step()\n",
    "\n",
    "logging.info(f\"Done training! Best PSNR {utils.save_checkpoint.best_score:.3f} obtained after step {utils.save_checkpoint.best_step}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3 = models.build_model(args)\n",
    "# model3.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_3minsep_08_14_20.pth\"))\n",
    "# model3.to(device)\n",
    "\n",
    "# model5 = models.build_model(args)\n",
    "# model5.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_08_13_20.pth\"))\n",
    "# model5.to(device)\n",
    "\n",
    "model10 = models.build_model(args)\n",
    "model10.load_state_dict(torch.load(\"models/trained/unet1d_partialconv_10kdata_30epoch_10minsep_08_14_20.pth\"))\n",
    "model10.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of first predicted point\n",
    "Comparison to global mean, receptive field mean, next visible point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_sep = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def first_pt_stats(model,min_sep):\n",
    "    _,_,test_loader = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.n_data,\n",
    "                                                   fix_datapoints=True,            \n",
    "                                                   min_sep = min_sep,\n",
    "                                                   test_num = 1)\n",
    "    print(\"Min_sep: {}\".format(min_sep))\n",
    "    print(\"*\"*30)\n",
    "    for batch_id,(clean,mask) in enumerate(test_loader):\n",
    "        print(\"Mean of clean signal: {:2.4f}\".format(clean.mean()))\n",
    "        outputs = model(clean.to(device),mask.to(device)).cpu()\n",
    "        print(\"Mean first value (min_sep=3): {:2.4f}\".format(outputs[:,:,0].mean()))\n",
    "\n",
    "    # Collect the \"means\" we're comparing to\n",
    "    mean_unmasked_sig = []\n",
    "    mean_rf_sig = []\n",
    "    first_unmasked = []\n",
    "\n",
    "    # Collect the diffs with the first value\n",
    "    mean_unmasked_sig_diff = []\n",
    "    mean_rf_sig_diff = []\n",
    "    first_unmasked_diff = []\n",
    "\n",
    "    mask_length = (64-mask.sum(axis=2))\n",
    "    for i in range(len(mask_length)):\n",
    "        # Mean of unmasked signal\n",
    "        mum = clean[i,0,int(mask_length[i]):].mean()\n",
    "        mean_unmasked_sig.append(mum)\n",
    "        # Mean of the unmasked receptive field \n",
    "        mrf = clean[i,0,int(mask_length[i]):21].mean()\n",
    "        mean_rf_sig.append(mrf)\n",
    "        # First unmasked value\n",
    "        fu = clean[i,0,int(mask_length[i])]\n",
    "        first_unmasked.append(fu)\n",
    "\n",
    "        # The diffs\n",
    "        mean_unmasked_sig_diff.append(abs(outputs[i,0,0]-mum).detach())\n",
    "        mean_rf_sig_diff.append(abs(outputs[i,0,0]-mrf).detach())\n",
    "        first_unmasked_diff.append(abs(outputs[i,0,0]-fu).detach())\n",
    "\n",
    "    print(\"Mean of full unmasked signal: {:2.4f}\".format(np.mean(mean_unmasked_sig)))\n",
    "    print(\"Mean of receptive field signal [0,21]: {:2.4f}\".format(np.mean(mean_rf_sig)))\n",
    "    print(\"Mean of first visible value after mask: {:2.4f}\".format(np.mean(first_unmasked)))\n",
    "\n",
    "    print(\"First predicted value mean diff: full unmasked signal: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(mean_unmasked_sig_diff),np.std(mean_unmasked_sig_diff)))\n",
    "    print(\"First predicted value mean diff: receptive field signal [0,21]: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(mean_rf_sig_diff),np.std(mean_rf_sig_diff)))\n",
    "    print(\"First predicted value mean diff: first visible value after mask: {:2.4f} (SD: {:2.4f})\"\\\n",
    "          .format(np.mean(first_unmasked_diff),np.std(first_unmasked_diff)))\n",
    "    \n",
    "    df_list = [min_sep,np.mean(mean_unmasked_sig),np.mean(mean_rf_sig),np.mean(first_unmasked),\n",
    "              float(outputs[:,:,0].mean().detach()),\n",
    "              np.mean(mean_unmasked_sig_diff),np.std(mean_unmasked_sig_diff),\n",
    "              np.mean(mean_rf_sig_diff),np.std(mean_rf_sig_diff),\n",
    "              np.mean(first_unmasked_diff),np.std(first_unmasked_diff)\n",
    "              ]\n",
    "    # print(\"Mean absolute diff of first predicted value and first visible after mask: {:2.4f}\".format(np.mean(first_pred_unmasked_diff)))\n",
    "    ### min_sep = 3\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list3 = first_pt_stats(model3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list5 = first_pt_stats(model5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_list10 = first_pt_stats(model10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([df_list3,df_list5,df_list10],columns = ['min_sep',\\\n",
    "                                      'clean_sig_mean','receptive_field_mean',\\\n",
    "                                      'first_visible_mean','first_pred_mean',\\\n",
    "                                      'full_unmasked_diff_mean','full_unmasked_diff_sd',\\\n",
    "                                      'receptive_field_diff_mean','receptive_field_diff_sd',\\\n",
    "                                      'first_visible_diff_mean','first_visible_diff_sd'\n",
    "                                     ]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Best PSNR 28.560\n",
    "def mask_idx_f(mask):\n",
    "    mask_start = int(np.argmin(mask[0]))\n",
    "    mask_length = int((1-mask[0]).sum())\n",
    "    mask_idx = range(mask_start,mask_start+mask_length)\n",
    "     # No mask indices\n",
    "    before = np.arange(mask.shape[2])[:mask_start]\n",
    "    after = np.arange(mask.shape[2])[mask_start+mask_length:]\n",
    "    no_mask_idx = np.append(before,after)\n",
    "    return mask_idx,before, after, mask_length, mask_start\n",
    "\n",
    "def print_one(loader,model):\n",
    "    np.random.seed()\n",
    "    clean,mask = next(iter(loader))\n",
    "    outputs = model(clean.to(device),mask.to(device)).cpu()\n",
    "    \n",
    "    mask_idx,before_mask,after_mask,mask_length, mask_start = mask_idx_f(mask)\n",
    "\n",
    "    outputs[0] * (1-mask[0]) + clean[0]*mask[0]    \n",
    "\n",
    "    out = outputs[0] * (1-mask[0]) + clean[0]*mask[0]\n",
    "    print(\"Mask Length: {}\\tMask Start: {}\".format(mask_length,mask_start))\n",
    "    \n",
    "    plt.figure(figsize=[15,10])\n",
    "    plt.subplot(3,1,1)\n",
    "    plt.plot(clean[0,0,:],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "    plt.title(\"True signal\")\n",
    "\n",
    "    plt.subplot(3,1,2)\n",
    "    masked = clean[0]*mask[0]\n",
    "    masked_plot = masked[:mask_start,]\n",
    "    plt.plot(before_mask,masked[0,before_mask],'xb')\n",
    "    plt.plot(after_mask,masked[0,after_mask],'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "\n",
    "    plt.title(\"Masked signal\")\n",
    "    plt.subplot(3,1,3)\n",
    "    plt.plot(out[0,:].detach(),'xb')\n",
    "    plt.plot(mask_idx,np.zeros(len(mask_idx)),'--k')\n",
    "    plt.plot(mask_idx,np.ones(len(mask_idx)),'--k')\n",
    "\n",
    "    plt.title(\"Denoised signal\")\n",
    "    \n",
    "    # Mean of the visible signal\n",
    "    sig_mean = clean[0,0,mask_length:21].mean()\n",
    "    print(\"First mask value: {:2.4f}\\nMean of full signal: {:2.4f}\\nMean of visible signal: {:2.4f}\"\\\n",
    "          .format(out[0,0],clean[0,0,:21].mean(),sig_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loader is shuffled and allows test_num to force a certain mask shape\n",
    "_,_,test_loader = data.build_dataset(args.dataset,\n",
    "                                                   args.n_data, \n",
    "                                                   batch_size=args.n_data,\n",
    "                                                   fix_datapoints=True,            \n",
    "                                                   min_sep = 10,\n",
    "                                                   test_num = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one(test_loader,model10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "              1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,1.,0.,0.,0.,0.,0.,0.,0.,0., \n",
    "              0., 1., 1., 1.,1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,m = next(iter(test_loader))\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "MODEL_PATH = \"models/trained/unet1d_partialconv_100kdata_100epoch_08_21_20.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
