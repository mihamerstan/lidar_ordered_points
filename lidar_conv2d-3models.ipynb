{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils\n",
    "\n",
    "import pandas as pd\n",
    "from laspy.file import File\n",
    "from pickle import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as udata\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import lidar_data_processing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.data_path= 'data' # not used\n",
    "        self.dataset= 'masked_pwc' # move lidar into datasets\n",
    "        self.batch_size= 64\n",
    "        self.model= 'lidar_unet2d'\n",
    "        self.in_channels = 3\n",
    "        self.out_channels = 1 # X only for now\n",
    "        self.lr= 0.005\n",
    "        self.weight_decay = 0.\n",
    "        self.num_epochs= 50\n",
    "        self.min_sep = 5 # not used\n",
    "        self.num_scan_lines = 1000\n",
    "        self.seq_len = 32\n",
    "        self.scan_line_gap_break = 7000 # threshold over which scan_gap indicates a new scan line\n",
    "        self.min_pt_count = 1700 # in a scan line, otherwise line not used\n",
    "        self.max_pt_count = 2000 # in a scan line, otherwise line not used\n",
    "        self.mask_pts_per_seq = 5\n",
    "        self.mask_consecutive = True\n",
    "        # points in between scan lines\n",
    "        self.stride_inline = 5\n",
    "        self.stride_across_lines = 3\n",
    "        self.valid_interval= 1 \n",
    "        self.save_interval= 1\n",
    "        self.seed = 0\n",
    "#         self.experiment_dir = 'lidar_experiments/2d'\n",
    "        self.output_dir= '../lidar_experiments/2d'\n",
    "#         self.checkpoint_dir= 'lidar_experiments/2d'\n",
    "        self.MODEL_PATH_LOAD = \"../lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Jan-19-12:46:12/checkpoints/checkpoint_best.pt\"\n",
    "        self.experiment= ''\n",
    "        self.resume_training= False\n",
    "        self.restore_file= None\n",
    "        self.no_save= False\n",
    "        self.step_checkpoints= False\n",
    "        self.no_log= False\n",
    "        self.log_interval= 100\n",
    "        self.no_visual= False\n",
    "        self.visual_interval= 100\n",
    "        self.no_progress= False\n",
    "        self.draft= False\n",
    "        self.dry_run= False\n",
    "        self.bias= False \n",
    "#         self.in_channels= 1 # maybe 6?\n",
    "        self.test_num = 0\n",
    "        # UNET\n",
    "        self.residual = False\n",
    "        self.wtd_loss = True\n",
    "        self.batch_norm = True\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-18 12:10:28] COMMAND: /home/michael/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py -f /home/michael/.local/share/jupyter/runtime/kernel-2a7bf6e2-1cc9-40c7-93cc-24c9d1d3eed2.json\n",
      "[2021-03-18 12:10:28] Arguments: {'data_path': 'data', 'dataset': 'masked_pwc', 'batch_size': 64, 'model': 'lidar_unet2d', 'in_channels': 3, 'out_channels': 1, 'lr': 0.005, 'weight_decay': 0.0, 'num_epochs': 50, 'min_sep': 5, 'num_scan_lines': 1000, 'seq_len': 32, 'scan_line_gap_break': 7000, 'min_pt_count': 1700, 'max_pt_count': 2000, 'mask_pts_per_seq': 5, 'mask_consecutive': True, 'stride_inline': 5, 'stride_across_lines': 3, 'valid_interval': 1, 'save_interval': 1, 'seed': 0, 'output_dir': '../lidar_experiments/2d', 'MODEL_PATH_LOAD': '../lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Jan-19-12:46:12/checkpoints/checkpoint_best.pt', 'experiment': 'lidar-unet2d-Mar-18-12:10:28', 'resume_training': False, 'restore_file': None, 'no_save': False, 'step_checkpoints': False, 'no_log': False, 'log_interval': 100, 'no_visual': False, 'visual_interval': 100, 'no_progress': False, 'draft': False, 'dry_run': False, 'bias': False, 'test_num': 0, 'residual': False, 'wtd_loss': True, 'batch_norm': True, 'experiment_dir': '../lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Mar-18-12:10:28', 'checkpoint_dir': '../lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Mar-18-12:10:28/checkpoints', 'log_dir': '../lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Mar-18-12:10:28/logs', 'log_file': '../lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Mar-18-12:10:28/logs/train.log'}\n"
     ]
    }
   ],
   "source": [
    "# gpu or cpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "args = utils.setup_experiment(args)\n",
    "utils.init_logging(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-18 12:10:29] Built 3 models consisting of 235,456 parameters each\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv1): PartialConv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (conv2): PartialConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv3): PartialConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv4): PartialConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv5): PartialConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "  (conv6): PartialConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "  (conv7): PartialConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv8): PartialConv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv9): PartialConv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "# MODEL_PATH = \"models/lidar/conv1d_256seq_400epochs_092620.pth\"\n",
    "# torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "# Loading models\n",
    "\n",
    "train_new_model = True\n",
    "\n",
    "# Build data loaders, a model and an optimizer\n",
    "if train_new_model:\n",
    "    model_x = models.build_model(args).to(device)\n",
    "    model_y = models.build_model(args).to(device)\n",
    "    model_z = models.build_model(args).to(device)\n",
    "else:\n",
    "    #NOTE: The 3 models need separate MODEL_PATH_LOAD filepaths\n",
    "    model_x = models.build_model(args)\n",
    "    model_x.load_state_dict(torch.load(args.MODEL_PATH_LOAD)['model'][0])\n",
    "    model_x.to(device)\n",
    "\n",
    "    model_y = models.build_model(args)\n",
    "    model_y.load_state_dict(torch.load(args.MODEL_PATH_LOAD)['model'][0])\n",
    "    model_y.to(device)\n",
    "\n",
    "    model_z = models.build_model(args)\n",
    "    model_z.load_state_dict(torch.load(args.MODEL_PATH_LOAD)['model'][0])\n",
    "    model_z.to(device)\n",
    "\n",
    "print(model_x)\n",
    "\n",
    "optimizer_x = torch.optim.Adam(model_x.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "optimizer_y = torch.optim.Adam(model_y.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "optimizer_z = torch.optim.Adam(model_z.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "scheduler_x = torch.optim.lr_scheduler.MultiStepLR(optimizer_x,milestones=[5,15,30,50,500], gamma=0.5)\n",
    "scheduler_y = torch.optim.lr_scheduler.MultiStepLR(optimizer_y,milestones=[5,15,30,50,500], gamma=0.5)\n",
    "scheduler_z = torch.optim.lr_scheduler.MultiStepLR(optimizer_z,milestones=[5,15,30,50,500], gamma=0.5)\n",
    "logging.info(f\"Built 3 models consisting of {sum(p.numel() for p in model_x.parameters()):,} parameters each\")\n",
    "\n",
    "# if args.resume_training:\n",
    "#     state_dict = utils.load_checkpoint(args, model_x, optimizer, scheduler)\n",
    "#     global_step = state_dict['last_step']\n",
    "#     start_epoch = int(state_dict['last_step']/(403200/state_dict['args'].batch_size))+1\n",
    "# else:\n",
    "global_step = -1\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pts files\n",
    "`scan_line_tensor` is the data file, a 3-D tensor of size [num_scan_lines,pts_per_scan_line,num_feats].  \n",
    "`idx_lists` indicate the top left corner of each training or validation square.  \n",
    "`sc` is the minmaxscaler used to generate the training set. Needed here to calculate weightedMSELoss at real scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loads as a list of numpy arrays\n",
    "scan_line_tensor = torch.load('../lidar_data/old_bad/32_32/'+'scan_line_tensor.pts')\n",
    "train_idx_list = torch.load('../lidar_data/old_bad/32_32/'+'train_idx_list.pts')\n",
    "valid_idx_list = torch.load('../lidar_data/old_bad/32_32/'+'valid_idx_list.pts')\n",
    "sc = torch.load('../lidar_data/old_bad/32_32/'+'sc.pts')\n",
    "scan_line_tensor = scan_line_tensor[:,:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask(sample,mask_pts_per_seq,consecutive=True):\n",
    "    # Given a 3-D tensor of all ones, returns a mask_tensor of same shape \n",
    "    # with random masking determined by mask_pts_per_seq\n",
    "    mask_tensor = torch.ones(sample.shape)\n",
    "    seq_len = mask_tensor.shape[0]\n",
    "    \n",
    "    if consecutive:\n",
    "        # Creates a square of missing points\n",
    "        first_mask = int(np.random.choice(np.arange(8,seq_len-8-mask_pts_per_seq),1))\n",
    "        \n",
    "        mask_tensor[first_mask:first_mask+mask_pts_per_seq,first_mask:first_mask+mask_pts_per_seq,:] = 0\n",
    "            \n",
    "    else:\n",
    "        # TO DO: Random points throughout the patch\n",
    "        for i in range(sample.shape[0]):\n",
    "            m[i,:] = np.random.choice(np.arange(8,seq_len-8),mask_pts_per_seq,replace=False)\n",
    "\n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader class\n",
    "class LidarLstmDataset(udata.Dataset):\n",
    "    def __init__(self, scan_line_tensor, idx_list, seq_len = 64, mask_pts_per_seq = 5, consecutive = True):\n",
    "        super(LidarLstmDataset, self).__init__()\n",
    "        self.scan_line_tensor = scan_line_tensor\n",
    "        self.idx_list = idx_list\n",
    "        self.seq_len = seq_len\n",
    "        self.mask_pts_per_seq = mask_pts_per_seq\n",
    "        self.consecutive = consecutive\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        row = self.idx_list[index][0]\n",
    "        col = self.idx_list[index][1]\n",
    "        clean = self.scan_line_tensor[row:row+self.seq_len,col:col+self.seq_len,:]\n",
    "        mask = add_mask(clean,self.mask_pts_per_seq,self.consecutive)\n",
    "        return clean.permute(2,0,1), mask.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LidarLstmDataset(scan_line_tensor,train_idx_list,args.seq_len, args.mask_pts_per_seq)\n",
    "valid_dataset = LidarLstmDataset(scan_line_tensor,valid_idx_list,args.seq_len, args.mask_pts_per_seq)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, num_workers=4, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track moving average of loss values\n",
    "train_meters = {name: utils.RunningAverageMeter(0.98) for name in ([\"train_loss\"])}\n",
    "valid_meters = {name: utils.AverageMeter() for name in ([\"valid_loss\"])}\n",
    "writer = SummaryWriter(log_dir=args.experiment_dir) if not args.no_visual else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_loop_onedim(model,optimizer,scheduler,\n",
    "                      start_epoch=start_epoch,\n",
    "                      num_epochs=args.num_epochs,\n",
    "                      global_step=global_step,\n",
    "                      train_meters=train_meters,\n",
    "                      valid_meters=valid_meters,\n",
    "                      writer=writer):\n",
    "\n",
    "    # TRAINING - X ONLY\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        dim,model,optimizer,scheduler = dim_dict[axis]\n",
    "\n",
    "        if args.resume_training:\n",
    "            if epoch %1 == 0:\n",
    "                optimizer.param_groups[0][\"lr\"] /= 2\n",
    "                print('learning rate reduced by factor of 2')\n",
    "\n",
    "        train_bar = utils.ProgressBar(train_loader, epoch)\n",
    "        for meter in train_meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "    #     epoch_loss_sum = 0\n",
    "        for batch_id, (clean, mask) in enumerate(train_bar):\n",
    "            # dataloader returns [clean, mask] list\n",
    "            model.train()\n",
    "\n",
    "            global_step += 1\n",
    "            inputs = clean.to(device)\n",
    "            mask_inputs = mask.to(device)\n",
    "            # only use the mask part of the outputs\n",
    "            raw_outputs = torch.zeros(mask_inputs[:,:3,:,:].shape).to(device)\n",
    "\n",
    "            raw_axis = model(inputs,mask_inputs)\n",
    "\n",
    "            raw_outputs[:,dim,:,:] = raw_axis[:,0,:,:]\n",
    "            outputs = (1-mask_inputs[:,:3,:,:])*raw_outputs + mask_inputs[:,:3,:,:]*inputs[:,:3,:,:]\n",
    "\n",
    "            # Dimension-specific loss, doesn't need to be scaled because they aren't combined\n",
    "            loss = 1000*F.mse_loss(outputs[:,dim,:,:], inputs[:,dim,:,:], reduction=\"sum\") / \\\n",
    "                   (inputs.size(0) * (args.mask_pts_per_seq**2))\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    #         epoch_loss_sum += loss * inputs.size(0)\n",
    "            train_meters[\"train_loss\"].update(loss)\n",
    "            train_bar.log(dict(**train_meters, lr=optimizer.param_groups[0][\"lr\"]), verbose=True)\n",
    "\n",
    "            if writer is not None and global_step % args.log_interval == 0:\n",
    "                writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], global_step)\n",
    "                writer.add_scalar(\"loss/train\", loss.item(), global_step)\n",
    "                gradients = torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None], dim=0)\n",
    "                writer.add_histogram(\"gradients\", gradients, global_step)\n",
    "                sys.stdout.flush()\n",
    "    #     epoch_loss = epoch_loss_sum / len(train_loader.dataset)\n",
    "\n",
    "        if epoch % args.valid_interval == 0:\n",
    "            model.eval()\n",
    "            for meter in valid_meters.values():\n",
    "                meter.reset()\n",
    "\n",
    "            valid_bar = utils.ProgressBar(valid_loader)\n",
    "            val_loss = 0\n",
    "            for sample_id, (clean, mask) in enumerate(valid_bar):\n",
    "                with torch.no_grad():\n",
    "                    inputs = clean.to(device)\n",
    "                    mask_inputs = mask.to(device)\n",
    "                    # only use the mask part of the outputs\n",
    "                    raw_outputs = torch.zeros(mask_inputs[:,:3,:,:].shape).to(device)\n",
    "\n",
    "                    raw_dim = model(inputs,mask_inputs)\n",
    "\n",
    "                    raw_outputs[:,0,:,:] = raw_dim[:,0,:,:]\n",
    "                    outputs = (1-mask_inputs[:,:3,:,:])*raw_outputs + mask_inputs[:,:3,:,:]*inputs[:,:3,:,:]\n",
    "\n",
    "                    val_loss = 1000*F.mse_loss(outputs[:,0,:,:], inputs[:,0,:,:], reduction=\"sum\") / \\\n",
    "                   (inputs.size(0) * (args.mask_pts_per_seq**2))\n",
    "\n",
    "                    valid_meters[\"valid_loss\"].update(val_loss.item())\n",
    "\n",
    "            if writer is not None:\n",
    "                writer.add_scalar(\"loss/valid\", valid_meters['valid_loss'].avg, global_step)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            logging.info(train_bar.print(dict(**train_meters, **valid_meters, lr=optimizer.param_groups[0][\"lr\"])))\n",
    "            utils.save_checkpoint(args, global_step, model, optimizer, score=valid_meters[\"valid_loss\"].avg, mode=\"min\")\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    logging.info(f\"Done training! Best Loss {utils.save_checkpoint.best_score:.3f} obtained after step {utils.save_checkpoint.best_step}.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "epoch 00:   0%|          | 0/1178 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X model done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-18 12:35:37] epoch 00 | train_loss 0.001 | valid_loss 0.002 | lr 0.001                  \n",
      "[2021-03-18 12:36:25] epoch 01 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:37:14] epoch 02 | train_loss 0.001 | valid_loss 0.002 | lr 6.3e-04                  \n",
      "[2021-03-18 12:38:03] epoch 03 | train_loss 0.002 | valid_loss 0.003 | lr 6.3e-04                  \n",
      "[2021-03-18 12:38:52] epoch 04 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:39:41] epoch 05 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:40:30] epoch 06 | train_loss 0.001 | valid_loss 0.002 | lr 6.3e-04                  \n",
      "[2021-03-18 12:41:19] epoch 07 | train_loss 0.001 | valid_loss 0.002 | lr 6.3e-04                  \n",
      "[2021-03-18 12:42:08] epoch 08 | train_loss 0.001 | valid_loss 0.002 | lr 6.3e-04                  \n",
      "[2021-03-18 12:42:57] epoch 09 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:43:46] epoch 10 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:44:35] epoch 11 | train_loss 0.001 | valid_loss 0.002 | lr 6.3e-04                  \n",
      "[2021-03-18 12:45:24] epoch 12 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:46:13] epoch 13 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:47:01] epoch 14 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:47:50] epoch 15 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:48:39] epoch 16 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:49:28] epoch 17 | train_loss 0.000 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:50:17] epoch 18 | train_loss 0.001 | valid_loss 0.002 | lr 6.3e-04                  \n",
      "[2021-03-18 12:51:05] epoch 19 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:51:55] epoch 20 | train_loss 0.001 | valid_loss 0.001 | lr 6.3e-04                  \n",
      "[2021-03-18 12:52:43] epoch 21 | train_loss 0.000 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:53:33] epoch 22 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:54:22] epoch 23 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:55:11] epoch 24 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:55:11] Done training! Best Loss 0.001 obtained after step 29449.\n",
      "epoch 00:   0%|          | 0/1178 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y model done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-18 12:55:59] epoch 00 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:56:48] epoch 01 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:57:37] epoch 02 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:58:25] epoch 03 | train_loss 0.001 | valid_loss 0.002 | lr 3.1e-04                  \n",
      "[2021-03-18 12:59:13] epoch 04 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 12:59:58] epoch 05 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:00:44] epoch 06 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:01:30] epoch 07 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:02:15] epoch 08 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:03:01] epoch 09 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:03:46] epoch 10 | train_loss 0.000 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:04:31] epoch 11 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:05:17] epoch 12 | train_loss 0.000 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:06:03] epoch 13 | train_loss 0.000 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:06:49] epoch 14 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:07:35] epoch 15 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:08:20] epoch 16 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:09:05] epoch 17 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:09:51] epoch 18 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:10:37] epoch 19 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:11:22] epoch 20 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:12:08] epoch 21 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:12:53] epoch 22 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:13:39] epoch 23 | train_loss 0.001 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:14:25] epoch 24 | train_loss 0.000 | valid_loss 0.001 | lr 3.1e-04                  \n",
      "[2021-03-18 13:14:25] Done training! Best Loss 0.001 obtained after step 11779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z model done\n"
     ]
    }
   ],
   "source": [
    "# model_x = train_loop_onedim(model_x,optimizer_x,scheduler_x,num_epochs=25)\n",
    "print(\"X model done\")\n",
    "model_y = train_loop_onedim(model_y,optimizer_y,scheduler_y,num_epochs=25)\n",
    "print(\"Y model done\")\n",
    "model_z = train_loop_onedim(model_z,optimizer_z,scheduler_z,num_epochs=25)\n",
    "print(\"Z model done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: alternate between the 3 axes in second round of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_onedim(model_x,model_y,model_z,inputs,mask):\n",
    "    raw_x = model_x(inputs,mask)[:,0,:,:]\n",
    "    raw_y = model_y(inputs,mask)[:,0,:,:]\n",
    "    raw_z = model_z(inputs,mask)[:,0,:,:]\n",
    "    raw_output = torch.zeros(mask[:,:3,:].shape).to(device)\n",
    "    raw_output[:,0,:,:] = raw_x\n",
    "    raw_output[:,1,:,:] = raw_y\n",
    "    raw_output[:,2,:,:] = raw_z\n",
    "    output_model = (1-mask[:,:3,:])*raw_output + mask[:,:3,:]*inputs[:,:3,:]\n",
    "    return output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single output example\n",
    "i,m = next(iter(train_loader))\n",
    "inputs = i.to(device)\n",
    "mask = m.to(device)\n",
    "output_model = predict_onedim(model_x,model_y,model_z,inputs,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0,0,10:20,10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 70325 is out of bounds for dimension 0 with size 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0d0019b6ffda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0moutput_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m70325\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 70325 is out of bounds for dimension 0 with size 128"
     ]
    }
   ],
   "source": [
    "(output_model - inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines\n",
    "First: Interpolate between last and next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a loss function that weights the loss according to coordinate ranges (xmax-xmin, ymax-ymin, zmax-zmin)\n",
    "def weighted_MSELoss(pred,true,sc,mask_pts_per_seq=args.mask_pts_per_seq):\n",
    "    '''weighted_MSELoss reconverts MSE loss back to the original scale of x,y,z.\n",
    "    Rationale is because xyz have such different ranges, we don't want to ignore the ones with largest scale.\n",
    "    Assumes that x,y,z are the first 3 features in sc scaler'''\n",
    "    \n",
    "    ranges = torch.Tensor(sc.data_max_[:3]-sc.data_min_[:3])\n",
    "    raw_loss = torch.zeros(3,dtype=float)\n",
    "    for i in range(3):\n",
    "        raw_loss[i] = F.mse_loss(pred[:,i,:,:], true[:,i,:,:], reduction=\"sum\") \n",
    "    return (ranges**2 * raw_loss).sum() #/ (pred.shape[0]*mask_pts_per_seq**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "# model_cpu = model.to('cpu')\n",
    "def loss_comparison(loader,model_x,model_y,model_z,\n",
    "                    mask_pts_per_seq=args.mask_pts_per_seq,pt_count=len(valid_dataset)):\n",
    "    wtd_loss = True\n",
    "    loss_model = 0\n",
    "    loss_interp = 0\n",
    "    for batch_id, (i, m) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            # conv1D model\n",
    "            inputs = i.to(device)\n",
    "            mask = m.to(device)\n",
    "            output_model = predict_onedim(model_x,model_y,model_z,inputs,mask)\n",
    "#             raw_outputs = torch.zeros(mask_inputs[:,:3,:,:].shape).to(device)\n",
    "#             raw_x = model(inputs,mask_inputs)\n",
    "#             raw_outputs[:,0,:,:] = raw_x[:,0,:,:]\n",
    "#             output_model = (1-mask_inputs[:,:3,:,:])*raw_outputs + mask_inputs[:,:3,:,:]*inputs[:,:3,:,:]\n",
    "            \n",
    "            # Interpolation\n",
    "            output_interp = lidar_data_processing.outer_interp_loop(i,m,mask_pts_per_seq,2)\n",
    "            wtd_loss=True\n",
    "            if wtd_loss:\n",
    "                loss_model+=weighted_MSELoss(output_model,inputs[:,:3,:],sc)\n",
    "                loss_interp+=weighted_MSELoss(output_interp,i[:,:3,:],sc)\n",
    "            else:\n",
    "                # normalized by the number of masked points\n",
    "                loss_model += F.mse_loss(output_model, inputs[:,:3,:], reduction=\"sum\") \n",
    "                loss_interp += F.mse_loss(output_interp, i[:,:3,:], reduction=\"sum\") \n",
    "        print(\"Batch {} done\".format(batch_id))\n",
    "\n",
    "    # Normalize by number of batches\n",
    "    loss_model = loss_model/((mask_pts_per_seq**2)*pt_count)\n",
    "    loss_interp = loss_interp/((mask_pts_per_seq**2)*pt_count)\n",
    "    print(\"Validation Loss\\n\",\"*\"*30)\n",
    "    print(\"Model: {:2.2f}\".format(loss_model))\n",
    "    print(\"Interpolation: {:2.2f}\".format(loss_interp))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f85171ff0685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 done\n",
      "Batch 1 done\n",
      "Batch 2 done\n",
      "Batch 3 done\n",
      "Batch 4 done\n",
      "Batch 5 done\n",
      "Batch 6 done\n",
      "Batch 7 done\n",
      "Batch 8 done\n",
      "Batch 9 done\n",
      "Batch 10 done\n",
      "Batch 11 done\n",
      "Batch 12 done\n",
      "Batch 13 done\n",
      "Batch 14 done\n",
      "Batch 15 done\n",
      "Batch 16 done\n",
      "Batch 17 done\n",
      "Batch 18 done\n",
      "Batch 19 done\n",
      "Batch 20 done\n",
      "Batch 21 done\n",
      "Batch 22 done\n",
      "Batch 23 done\n",
      "Batch 24 done\n",
      "Batch 25 done\n",
      "Batch 26 done\n",
      "Batch 27 done\n",
      "Batch 28 done\n",
      "Batch 29 done\n",
      "Batch 30 done\n",
      "Batch 31 done\n",
      "Batch 32 done\n",
      "Batch 33 done\n",
      "Batch 34 done\n",
      "Batch 35 done\n",
      "Batch 36 done\n",
      "Batch 37 done\n",
      "Batch 38 done\n",
      "Batch 39 done\n",
      "Batch 40 done\n",
      "Batch 41 done\n",
      "Batch 42 done\n",
      "Batch 43 done\n",
      "Batch 44 done\n",
      "Batch 45 done\n",
      "Batch 46 done\n",
      "Batch 47 done\n",
      "Batch 48 done\n",
      "Batch 49 done\n",
      "Batch 50 done\n",
      "Batch 51 done\n",
      "Batch 52 done\n",
      "Batch 53 done\n",
      "Batch 54 done\n",
      "Batch 55 done\n",
      "Batch 56 done\n",
      "Batch 57 done\n",
      "Batch 58 done\n",
      "Batch 59 done\n",
      "Batch 60 done\n",
      "Batch 61 done\n",
      "Batch 62 done\n",
      "Batch 63 done\n",
      "Batch 64 done\n",
      "Batch 65 done\n",
      "Batch 66 done\n",
      "Batch 67 done\n",
      "Batch 68 done\n",
      "Batch 69 done\n",
      "Batch 70 done\n",
      "Batch 71 done\n",
      "Batch 72 done\n",
      "Batch 73 done\n",
      "Batch 74 done\n",
      "Batch 75 done\n",
      "Batch 76 done\n",
      "Batch 77 done\n",
      "Batch 78 done\n",
      "Batch 79 done\n",
      "Batch 80 done\n",
      "Batch 81 done\n",
      "Batch 82 done\n",
      "Batch 83 done\n",
      "Batch 84 done\n",
      "Batch 85 done\n",
      "Batch 86 done\n",
      "Batch 87 done\n",
      "Batch 88 done\n",
      "Batch 89 done\n",
      "Batch 90 done\n",
      "Batch 91 done\n",
      "Batch 92 done\n",
      "Batch 93 done\n",
      "Batch 94 done\n",
      "Batch 95 done\n",
      "Batch 96 done\n",
      "Batch 97 done\n",
      "Batch 98 done\n",
      "Batch 99 done\n",
      "Batch 100 done\n",
      "Batch 101 done\n",
      "Batch 102 done\n",
      "Batch 103 done\n",
      "Batch 104 done\n",
      "Batch 105 done\n",
      "Batch 106 done\n",
      "Batch 107 done\n",
      "Batch 108 done\n",
      "Batch 109 done\n",
      "Batch 110 done\n",
      "Batch 111 done\n",
      "Batch 112 done\n",
      "Batch 113 done\n",
      "Batch 114 done\n",
      "Batch 115 done\n",
      "Batch 116 done\n",
      "Batch 117 done\n",
      "Batch 118 done\n",
      "Batch 119 done\n",
      "Batch 120 done\n",
      "Batch 121 done\n",
      "Batch 122 done\n",
      "Batch 123 done\n",
      "Batch 124 done\n",
      "Batch 125 done\n",
      "Batch 126 done\n",
      "Batch 127 done\n",
      "Batch 128 done\n",
      "Batch 129 done\n",
      "Batch 130 done\n",
      "Batch 131 done\n",
      "Batch 132 done\n",
      "Batch 133 done\n",
      "Batch 134 done\n",
      "Batch 135 done\n",
      "Batch 136 done\n",
      "Batch 137 done\n",
      "Batch 138 done\n",
      "Batch 139 done\n",
      "Batch 140 done\n",
      "Batch 141 done\n",
      "Batch 142 done\n",
      "Batch 143 done\n",
      "Batch 144 done\n",
      "Batch 145 done\n",
      "Batch 146 done\n",
      "Batch 147 done\n",
      "Batch 148 done\n",
      "Batch 149 done\n",
      "Batch 150 done\n",
      "Batch 151 done\n",
      "Batch 152 done\n",
      "Batch 153 done\n",
      "Batch 154 done\n",
      "Batch 155 done\n",
      "Batch 156 done\n",
      "Batch 157 done\n",
      "Batch 158 done\n",
      "Batch 159 done\n",
      "Batch 160 done\n",
      "Batch 161 done\n",
      "Batch 162 done\n",
      "Batch 163 done\n",
      "Batch 164 done\n",
      "Batch 165 done\n",
      "Batch 166 done\n",
      "Batch 167 done\n",
      "Batch 168 done\n",
      "Batch 169 done\n",
      "Batch 170 done\n",
      "Batch 171 done\n",
      "Batch 172 done\n",
      "Batch 173 done\n",
      "Batch 174 done\n",
      "Batch 175 done\n",
      "Batch 176 done\n",
      "Batch 177 done\n",
      "Batch 178 done\n",
      "Batch 179 done\n",
      "Batch 180 done\n",
      "Batch 181 done\n",
      "Batch 182 done\n",
      "Batch 183 done\n",
      "Batch 184 done\n",
      "Batch 185 done\n",
      "Batch 186 done\n",
      "Batch 187 done\n",
      "Batch 188 done\n",
      "Batch 189 done\n",
      "Batch 190 done\n",
      "Batch 191 done\n",
      "Batch 192 done\n",
      "Batch 193 done\n",
      "Batch 194 done\n",
      "Batch 195 done\n",
      "Batch 196 done\n",
      "Batch 197 done\n",
      "Batch 198 done\n",
      "Batch 199 done\n",
      "Batch 200 done\n",
      "Batch 201 done\n",
      "Batch 202 done\n",
      "Batch 203 done\n",
      "Batch 204 done\n",
      "Batch 205 done\n",
      "Batch 206 done\n",
      "Batch 207 done\n",
      "Batch 208 done\n",
      "Batch 209 done\n",
      "Batch 210 done\n",
      "Batch 211 done\n",
      "Batch 212 done\n",
      "Batch 213 done\n",
      "Batch 214 done\n",
      "Batch 215 done\n",
      "Batch 216 done\n",
      "Batch 217 done\n",
      "Batch 218 done\n",
      "Batch 219 done\n",
      "Batch 220 done\n",
      "Batch 221 done\n",
      "Batch 222 done\n",
      "Batch 223 done\n",
      "Batch 224 done\n",
      "Batch 225 done\n",
      "Batch 226 done\n",
      "Batch 227 done\n",
      "Batch 228 done\n",
      "Batch 229 done\n",
      "Batch 230 done\n",
      "Batch 231 done\n",
      "Batch 232 done\n",
      "Batch 233 done\n",
      "Batch 234 done\n",
      "Batch 235 done\n",
      "Batch 236 done\n",
      "Batch 237 done\n",
      "Batch 238 done\n",
      "Batch 239 done\n",
      "Batch 240 done\n",
      "Batch 241 done\n",
      "Batch 242 done\n",
      "Batch 243 done\n",
      "Batch 244 done\n",
      "Batch 245 done\n",
      "Batch 246 done\n",
      "Batch 247 done\n",
      "Batch 248 done\n",
      "Batch 249 done\n",
      "Batch 250 done\n",
      "Batch 251 done\n",
      "Batch 252 done\n",
      "Batch 253 done\n",
      "Batch 254 done\n",
      "Batch 255 done\n",
      "Batch 256 done\n",
      "Batch 257 done\n",
      "Batch 258 done\n",
      "Batch 259 done\n",
      "Batch 260 done\n",
      "Batch 261 done\n",
      "Batch 262 done\n",
      "Batch 263 done\n",
      "Batch 264 done\n",
      "Batch 265 done\n",
      "Batch 266 done\n",
      "Batch 267 done\n",
      "Batch 268 done\n",
      "Batch 269 done\n",
      "Batch 270 done\n",
      "Batch 271 done\n",
      "Batch 272 done\n",
      "Batch 273 done\n",
      "Batch 274 done\n",
      "Batch 275 done\n",
      "Batch 276 done\n",
      "Batch 277 done\n",
      "Batch 278 done\n",
      "Batch 279 done\n",
      "Batch 280 done\n",
      "Batch 281 done\n",
      "Batch 282 done\n",
      "Batch 283 done\n",
      "Batch 284 done\n",
      "Batch 285 done\n",
      "Batch 286 done\n",
      "Batch 287 done\n",
      "Batch 288 done\n",
      "Batch 289 done\n",
      "Batch 290 done\n",
      "Batch 291 done\n",
      "Batch 292 done\n",
      "Batch 293 done\n",
      "Batch 294 done\n",
      "Validation Loss\n",
      " ******************************\n",
      "Model: 1445339.40\n",
      "Interpolation: 15.56\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "# loss_comparison(train_loader,model)\n",
    "loss_comparison(train_loader,model_x,model_y,model_z,pt_count=len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 done\n",
      "Batch 1 done\n",
      "Batch 2 done\n",
      "Batch 3 done\n",
      "Batch 4 done\n",
      "Batch 5 done\n",
      "Batch 6 done\n",
      "Batch 7 done\n",
      "Batch 8 done\n",
      "Batch 9 done\n",
      "Batch 10 done\n",
      "Batch 11 done\n",
      "Batch 12 done\n",
      "Batch 13 done\n",
      "Batch 14 done\n",
      "Batch 15 done\n",
      "Batch 16 done\n",
      "Batch 17 done\n",
      "Batch 18 done\n",
      "Batch 19 done\n",
      "Batch 20 done\n",
      "Batch 21 done\n",
      "Batch 22 done\n",
      "Batch 23 done\n",
      "Batch 24 done\n",
      "Batch 25 done\n",
      "Batch 26 done\n",
      "Batch 27 done\n",
      "Batch 28 done\n",
      "Batch 29 done\n",
      "Batch 30 done\n",
      "Batch 31 done\n",
      "Batch 32 done\n",
      "Batch 33 done\n",
      "Batch 34 done\n",
      "Batch 35 done\n",
      "Batch 36 done\n",
      "Batch 37 done\n",
      "Batch 38 done\n",
      "Batch 39 done\n",
      "Batch 40 done\n",
      "Batch 41 done\n",
      "Batch 42 done\n",
      "Batch 43 done\n",
      "Batch 44 done\n",
      "Batch 45 done\n",
      "Batch 46 done\n",
      "Batch 47 done\n",
      "Batch 48 done\n",
      "Batch 49 done\n",
      "Batch 50 done\n",
      "Batch 51 done\n",
      "Batch 52 done\n",
      "Batch 53 done\n",
      "Batch 54 done\n",
      "Batch 55 done\n",
      "Batch 56 done\n",
      "Batch 57 done\n",
      "Batch 58 done\n",
      "Batch 59 done\n",
      "Batch 60 done\n",
      "Batch 61 done\n",
      "Batch 62 done\n",
      "Batch 63 done\n",
      "Batch 64 done\n",
      "Batch 65 done\n",
      "Batch 66 done\n",
      "Batch 67 done\n",
      "Validation Loss\n",
      " ******************************\n",
      "Model: 1756487.31\n",
      "Interpolation: 27.37\n"
     ]
    }
   ],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "# loss_comparison(train_loader,model)\n",
    "loss_comparison(valid_loader,model_x,model_y,model_z,pt_count=len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,mask_inputs = next(iter(valid_loader))\n",
    "# only use the mask part of the outputs\n",
    "\n",
    "raw_outputs = torch.zeros(mask_inputs[:,:3,:,:].shape).to(device)\n",
    "raw_x = model(inputs.to(device),mask_inputs.to(device))\n",
    "raw_outputs[:,0,:,:] = raw_x[:,0,:,:]\n",
    "outputs = (1-mask_inputs[:,:3,:,:])*raw_outputs.to('cpu') + mask_inputs[:,:3,:,:]*inputs[:,:3,:,:]\n",
    "\n",
    "output_interp = lidar_data_processing.outer_interp_loop(inputs,mask_inputs,args.mask_pts_per_seq,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "im_idx = 28\n",
    "\n",
    "def plot_infill(clean,output,mask,label_key = 'z'):\n",
    "    ''' Plotting function for 2D infill. Takes a single patch for clean,output, \n",
    "    and mask, and a label_key indicating which value (x,y, or z) to display.    \n",
    "    '''\n",
    "    # Which dimension to plot\n",
    "    xyz_dict = {'x':2,'y':3,'z':4}\n",
    "    z_val = xyz_dict[label_key]\n",
    "    # Set up plot\n",
    "    fig = plt.figure(figsize=[12,12])\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot unmasked points\n",
    "    surrounding_no_mask = mask[0] != 0\n",
    "    unmasked_arr = np.array(lidar_data_processing.surrounding_grid(clean,surrounding_no_mask))\n",
    "    ax.scatter(unmasked_arr[:,0],unmasked_arr[:,1],unmasked_arr[:,z_val], marker='+')\n",
    "\n",
    "    # Plot masked, filled points\n",
    "    surrounding_mask = mask[0] == 0\n",
    "    filled_arr = np.array(lidar_data_processing.surrounding_grid(output,surrounding_mask))\n",
    "    ax.scatter(filled_arr[:,0],filled_arr[:,1],filled_arr[:,z_val], color='r', marker='o')\n",
    "\n",
    "    # Plot original, masked points\n",
    "    masked_arr = np.array(lidar_data_processing.surrounding_grid(clean,surrounding_mask))\n",
    "    ax.scatter(masked_arr[:,0],masked_arr[:,1],masked_arr[:,z_val], color='g', marker='o')\n",
    "\n",
    "    # Labels and such\n",
    "    ax.set_xlabel('Grid Across-Flight',fontsize=15)\n",
    "    ax.set_ylabel('Grid Along-Flight',fontsize=15)\n",
    "    ax.set_zlabel(label_key+' value',fontsize=15)\n",
    "\n",
    "    plt.show()\n",
    "#     print(output.shape)\n",
    "#     print(clean.shape)\n",
    "#     print(weighted_MSELoss(output.unsqueeze(0),clean[:,:3,:].unsqueeze(0),sc))\n",
    "          \n",
    "plot_infill(inputs[im_idx],outputs[im_idx],mask_inputs[im_idx],'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_infill(inputs[im_idx],output_interp[im_idx],mask_inputs[im_idx],'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "# Configure the trace.\n",
    "trace = go.Scatter3d(\n",
    "    x=outputs.detach()[0,0,:,5],  # <-- Put your data instead\n",
    "    y=outputs.detach()[0,1,:,5],  # <-- Put your data instead\n",
    "    z=outputs.detach()[0,2,:,5],  # <-- Put your data instead\n",
    "    mode='markers',\n",
    "    marker={\n",
    "        'size': 10,\n",
    "        'opacity': 0.8,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure the layout.\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0}\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Render the plot.\n",
    "plotly.offline.iplot(plot_figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
