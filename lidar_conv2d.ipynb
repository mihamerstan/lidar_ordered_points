{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils\n",
    "\n",
    "import pandas as pd\n",
    "from laspy.file import File\n",
    "from pickle import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as udata\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import lidar_data_processing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.data_path= 'data' # not used\n",
    "        self.dataset= 'masked_pwc' # move lidar into datasets\n",
    "        self.batch_size= 64\n",
    "        self.model= 'lidar_unet2d'\n",
    "        self.in_channels = 6\n",
    "        self.lr= 0.005\n",
    "        self.weight_decay = 0.\n",
    "        self.num_epochs= 50\n",
    "        self.min_sep = 5 # not used\n",
    "        self.num_scan_lines = 1000\n",
    "        self.seq_len = 32\n",
    "        self.scan_line_gap_break = 7000 # threshold over which scan_gap indicates a new scan line\n",
    "        self.min_pt_count = 1700 # in a scan line, otherwise line not used\n",
    "        self.max_pt_count = 2000 # in a scan line, otherwise line not used\n",
    "        self.mask_pts_per_seq = 5\n",
    "        self.mask_consecutive = True\n",
    "        # points in between scan lines\n",
    "        self.stride_inline = 5\n",
    "        self.stride_across_lines = 3\n",
    "        self.valid_interval= 1 \n",
    "        self.save_interval= 1\n",
    "        self.seed = 0\n",
    "#         self.experiment_dir = 'lidar_experiments/2d'\n",
    "        self.output_dir= 'lidar_experiments/2d'\n",
    "#         self.checkpoint_dir= 'lidar_experiments/2d'\n",
    "        self.experiment= ''\n",
    "        self.resume_training= False\n",
    "        self.restore_file= None\n",
    "        self.no_save= False\n",
    "        self.step_checkpoints= False\n",
    "        self.no_log= False\n",
    "        self.log_interval= 100\n",
    "        self.no_visual= False\n",
    "        self.visual_interval= 100\n",
    "        self.no_progress= False\n",
    "        self.draft= False\n",
    "        self.dry_run= False\n",
    "        self.bias= False \n",
    "#         self.in_channels= 1 # maybe 6?\n",
    "        self.test_num = 0\n",
    "        # UNET\n",
    "        self.residual = False\n",
    "        self.wtd_loss = True\n",
    "        self.batch_norm = True\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-08 18:22:50] COMMAND: /home/michael/python-virtual-environments/data/lib/python3.6/site-packages/ipykernel_launcher.py -f /home/michael/.local/share/jupyter/runtime/kernel-258a178a-849a-4f2c-9a29-bc65ef52961b.json\n",
      "[2020-11-08 18:22:50] Arguments: {'data_path': 'data', 'dataset': 'masked_pwc', 'batch_size': 64, 'model': 'lidar_unet2d', 'in_channels': 6, 'lr': 0.005, 'weight_decay': 0.0, 'num_epochs': 50, 'min_sep': 5, 'num_scan_lines': 1000, 'seq_len': 32, 'scan_line_gap_break': 7000, 'min_pt_count': 1700, 'max_pt_count': 2000, 'mask_pts_per_seq': 5, 'mask_consecutive': True, 'stride_inline': 5, 'stride_across_lines': 3, 'valid_interval': 1, 'save_interval': 1, 'seed': 0, 'output_dir': 'lidar_experiments/2d', 'experiment': 'lidar-unet2d-Nov-08-18:22:50', 'resume_training': False, 'restore_file': None, 'no_save': False, 'step_checkpoints': False, 'no_log': False, 'log_interval': 100, 'no_visual': False, 'visual_interval': 100, 'no_progress': False, 'draft': False, 'dry_run': False, 'bias': False, 'test_num': 0, 'residual': False, 'wtd_loss': True, 'batch_norm': True, 'experiment_dir': 'lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Nov-08-18:22:50', 'checkpoint_dir': 'lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Nov-08-18:22:50/checkpoints', 'log_dir': 'lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Nov-08-18:22:50/logs', 'log_file': 'lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Nov-08-18:22:50/logs/train.log'}\n"
     ]
    }
   ],
   "source": [
    "# gpu or cpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "args = utils.setup_experiment(args)\n",
    "utils.init_logging(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-08 18:22:51] Built a model consisting of 238,816 parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv1): PartialConv2d(6, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (conv2): PartialConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv3): PartialConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv4): PartialConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv5): PartialConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "  (conv6): PartialConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "  (conv7): PartialConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv8): PartialConv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv9): PartialConv2d(32, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (bn32): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn64): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Saving model\n",
    "# MODEL_PATH = \"models/lidar/conv1d_256seq_400epochs_092620.pth\"\n",
    "# torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "# Loading models\n",
    "MODEL_PATH_LOAD = \"lidar_experiments/2d/lidar_unet2d/lidar-unet2d-Nov-08-16:29:49/checkpoints/checkpoint_best.pt\"\n",
    "\n",
    "train_new_model = True\n",
    "\n",
    "# Build data loaders, a model and an optimizer\n",
    "if train_new_model:\n",
    "    model = models.build_model(args).to(device)\n",
    "else:\n",
    "    model = models.build_model(args)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH_LOAD)['model'][0])\n",
    "    model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay = args.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[5,15,30,50,500], gamma=0.5)\n",
    "logging.info(f\"Built a model consisting of {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "if args.resume_training:\n",
    "    state_dict = utils.load_checkpoint(args, model, optimizer, scheduler)\n",
    "    global_step = state_dict['last_step']\n",
    "    start_epoch = int(state_dict['last_step']/(403200/state_dict['args'].batch_size))+1\n",
    "else:\n",
    "    global_step = -1\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pts files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads as a list of numpy arrays\n",
    "scan_line_tensor = torch.load('../lidar_data/32_32/'+'scan_line_tensor.pts')\n",
    "train_idx_list = torch.load('../lidar_data/32_32/'+'train_idx_list.pts')\n",
    "valid_idx_list = torch.load('../lidar_data/32_32/'+'valid_idx_list.pts')\n",
    "sc = torch.load('../lidar_data/32_32/'+'sc.pts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask(sample,mask_pts_per_seq,consecutive=True):\n",
    "    # Given a 3-D tensor of all ones, returns a mask_tensor of same shape \n",
    "    # with random masking determined by mask_pts_per_seq\n",
    "    mask_tensor = torch.ones(sample.shape)\n",
    "    seq_len = mask_tensor.shape[0]\n",
    "    \n",
    "    if consecutive:\n",
    "        # Creates a square of missing points\n",
    "        first_mask = int(np.random.choice(np.arange(8,seq_len-8-mask_pts_per_seq),1))\n",
    "        \n",
    "        mask_tensor[first_mask:first_mask+mask_pts_per_seq,first_mask:first_mask+mask_pts_per_seq,:] = 0\n",
    "            \n",
    "    else:\n",
    "        # TO DO: Random points throughout the patch\n",
    "        for i in range(sample.shape[0]):\n",
    "            m[i,:] = np.random.choice(np.arange(8,seq_len-8),mask_pts_per_seq,replace=False)\n",
    "\n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader class\n",
    "class LidarLstmDataset(udata.Dataset):\n",
    "    def __init__(self, scan_line_tensor, idx_list, seq_len = 64, mask_pts_per_seq = 5, consecutive = True):\n",
    "        super(LidarLstmDataset, self).__init__()\n",
    "        self.scan_line_tensor = scan_line_tensor\n",
    "        self.idx_list = idx_list\n",
    "        self.seq_len = seq_len\n",
    "        self.mask_pts_per_seq = mask_pts_per_seq\n",
    "        self.consecutive = consecutive\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        row = self.idx_list[index][0]\n",
    "        col = self.idx_list[index][1]\n",
    "        clean = self.scan_line_tensor[row:row+self.seq_len,col:col+self.seq_len,:]\n",
    "        mask = add_mask(clean,self.mask_pts_per_seq,self.consecutive)\n",
    "        return clean.permute(2,0,1), mask.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LidarLstmDataset(scan_line_tensor,train_idx_list,args.seq_len, args.mask_pts_per_seq)\n",
    "valid_dataset = LidarLstmDataset(scan_line_tensor,valid_idx_list,args.seq_len, args.mask_pts_per_seq)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, num_workers=4, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function that weights the loss according to coordinate ranges (xmax-xmin, ymax-ymin, zmax-zmin)\n",
    "def weighted_MSELoss(pred,true,sc,mask_pts_per_seq=args.mask_pts_per_seq):\n",
    "    '''weighted_MSELoss reconverts MSE loss back to the original scale of x,y,z.\n",
    "    Rationale is because xyz have such different ranges, we don't want to ignore the ones with largest scale.\n",
    "    Assumes that x,y,z are the first 3 features in sc scaler'''\n",
    "    \n",
    "    ranges = torch.Tensor(sc.data_max_[:3]-sc.data_min_[:3])\n",
    "    raw_loss = torch.zeros(3,dtype=float)\n",
    "    for i in range(3):\n",
    "        raw_loss[i] = F.mse_loss(pred[:,i,:,:], true[:,i,:,:], reduction=\"sum\") \n",
    "    return (ranges**2 * raw_loss).sum() #/ (pred.shape[0]*mask_pts_per_seq**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.10) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# Track moving average of loss values\n",
    "train_meters = {name: utils.RunningAverageMeter(0.98) for name in ([\"train_loss\"])}\n",
    "valid_meters = {name: utils.AverageMeter() for name in ([\"valid_loss\"])}\n",
    "writer = SummaryWriter(log_dir=args.experiment_dir) if not args.no_visual else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 00:   6%|▌         | 73/1178 [00:02<00:33, 33.39it/s, train_loss=461380.911 (8196.253), lr=0.005]   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-52ce691ddbfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmask_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# only use the mask part of the outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mraw_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmask_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mraw_outputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/michael/bfcnn/lidar_ordered_points/models/lidar_unet2d_partialconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask_in)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# out = self.dropout(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mprelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/michael/python-virtual-environments/data/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/michael/bfcnn/lidar_ordered_points/models/PartialConv2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, mask_in)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_maskUpdater\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# for mixed precision training, change 1e-8 to 1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    if args.resume_training:\n",
    "        if epoch %1 == 0:\n",
    "            optimizer.param_groups[0][\"lr\"] /= 2\n",
    "            print('learning rate reduced by factor of 2')\n",
    "\n",
    "    train_bar = utils.ProgressBar(train_loader, epoch)\n",
    "    for meter in train_meters.values():\n",
    "        meter.reset()\n",
    "\n",
    "#     epoch_loss_sum = 0\n",
    "    for batch_id, (clean, mask) in enumerate(train_bar):\n",
    "        # dataloader returns [clean, mask] list\n",
    "        model.train()\n",
    "        global_step += 1\n",
    "        inputs = clean.to(device)\n",
    "        mask_inputs = mask.to(device)\n",
    "        # only use the mask part of the outputs\n",
    "        raw_outputs = model(inputs,mask_inputs)\n",
    "        outputs = (1-mask_inputs[:,:3,:,:])*raw_outputs + mask_inputs[:,:3,:,:]*inputs[:,:3,:,:]\n",
    "        \n",
    "        if args.wtd_loss:\n",
    "            loss = weighted_MSELoss(outputs,inputs[:,:3,:,:],sc)/(inputs.size(0)*(args.mask_pts_per_seq**2))\n",
    "            # Regularization?\n",
    "            \n",
    "        else:\n",
    "            # normalized by the number of masked points\n",
    "            loss = F.mse_loss(outputs, inputs[:,:3,:,:], reduction=\"sum\") / \\\n",
    "                   (inputs.size(0) * (args.mask_pts_per_seq**2))\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         epoch_loss_sum += loss * inputs.size(0)\n",
    "        train_meters[\"train_loss\"].update(loss)\n",
    "        train_bar.log(dict(**train_meters, lr=optimizer.param_groups[0][\"lr\"]), verbose=True)\n",
    "\n",
    "        if writer is not None and global_step % args.log_interval == 0:\n",
    "            writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], global_step)\n",
    "            writer.add_scalar(\"loss/train\", loss.item(), global_step)\n",
    "            gradients = torch.cat([p.grad.view(-1) for p in model.parameters() if p.grad is not None], dim=0)\n",
    "            writer.add_histogram(\"gradients\", gradients, global_step)\n",
    "            sys.stdout.flush()\n",
    "#     epoch_loss = epoch_loss_sum / len(train_loader.dataset)\n",
    "    \n",
    "    if epoch % args.valid_interval == 0:\n",
    "        model.eval()\n",
    "        for meter in valid_meters.values():\n",
    "            meter.reset()\n",
    "\n",
    "        valid_bar = utils.ProgressBar(valid_loader)\n",
    "        val_loss = 0\n",
    "        for sample_id, (clean, mask) in enumerate(valid_bar):\n",
    "            with torch.no_grad():\n",
    "                inputs = clean.to(device)\n",
    "                mask_inputs = mask.to(device)\n",
    "                # only use the mask part of the outputs\n",
    "                raw_output = model(inputs,mask_inputs)\n",
    "                output = (1-mask_inputs[:,:3,:,:])*raw_output + mask_inputs[:,:3,:,:]*inputs[:,:3,:,:]\n",
    "\n",
    "                # TO DO, only run loss on masked part of output\n",
    "                \n",
    "                if args.wtd_loss:\n",
    "                    val_loss = weighted_MSELoss(output,inputs[:,:3,:,:],sc)/(inputs.size(0)*(args.mask_pts_per_seq**2))\n",
    "                else:\n",
    "                    # normalized by the number of masked points\n",
    "                    val_loss = F.mse_loss(output, inputs[:,:3,:,:], reduction=\"sum\")/(inputs.size(0)* \\\n",
    "                                                                                    (args.mask_pts_per_seq**2))\n",
    "\n",
    "                valid_meters[\"valid_loss\"].update(val_loss.item())\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"loss/valid\", valid_meters['valid_loss'].avg, global_step)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        logging.info(train_bar.print(dict(**train_meters, **valid_meters, lr=optimizer.param_groups[0][\"lr\"])))\n",
    "        utils.save_checkpoint(args, global_step, model, optimizer, score=valid_meters[\"valid_loss\"].avg, mode=\"min\")\n",
    "    scheduler.step()\n",
    "\n",
    "logging.info(f\"Done training! Best Loss {utils.save_checkpoint.best_score:.3f} obtained after step {utils.save_checkpoint.best_step}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines\n",
    "First: Interpolate between last and next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "# model_cpu = model.to('cpu')\n",
    "def loss_comparison(loader,model,mask_pts_per_seq=args.mask_pts_per_seq,pt_count=len(valid_dataset)):\n",
    "    wtd_loss = True\n",
    "    loss_model = 0\n",
    "    loss_interp = 0\n",
    "    for batch_id, (i, m) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            # conv1D model\n",
    "            inputs = i.to(device)\n",
    "            mask = m.to(device)\n",
    "            raw_output = model(inputs,mask)\n",
    "            output_model = (1-mask[:,:3,:])*raw_output + mask[:,:3,:]*inputs[:,:3,:]\n",
    "            \n",
    "            # Interpolation\n",
    "            output_interp = lidar_data_processing.outer_interp_loop(i,m,mask_pts_per_seq,2)\n",
    "\n",
    "            if wtd_loss:\n",
    "                loss_model+=weighted_MSELoss(output_model,inputs[:,:3,:],sc)\n",
    "                loss_interp+=weighted_MSELoss(output_interp,i[:,:3,:],sc)\n",
    "            else:\n",
    "                # normalized by the number of masked points\n",
    "                loss_model += F.mse_loss(output_model, inputs[:,:3,:], reduction=\"sum\") \n",
    "                loss_interp += F.mse_loss(output_interp, i[:,:3,:], reduction=\"sum\") \n",
    "        print(\"Batch {} done\".format(batch_id))\n",
    "\n",
    "    # Normalize by number of batches\n",
    "    loss_model = loss_model/((mask_pts_per_seq**2)*pt_count)\n",
    "    loss_interp = loss_interp/((mask_pts_per_seq**2)*pt_count)\n",
    "    print(\"Validation Loss\\n\",\"*\"*30)\n",
    "    print(\"Model: {:2.2f}\".format(loss_model))\n",
    "    print(\"Interpolation: {:2.2f}\".format(loss_interp))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "# loss_comparison(train_loader,model)\n",
    "loss_comparison(valid_loader,model,pt_count=len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,mask_inputs = next(iter(train_loader))\n",
    "# only use the mask part of the outputs\n",
    "raw_outputs = model(inputs.to(device),mask_inputs.to(device))\n",
    "outputs = (1-mask_inputs[:,:3,:,:])*raw_outputs.to('cpu') + mask_inputs[:,:3,:,:]*inputs[:,:3,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "im_idx = 10\n",
    "\n",
    "def plot_infill(clean,output,mask,label_key = 'z'):\n",
    "    ''' Plotting function for 2D infill. Takes a single patch for clean,output, \n",
    "    and mask, and a label_key indicating which value (x,y, or z) to display.    \n",
    "    '''\n",
    "    # Which dimension to plot\n",
    "    xyz_dict = {'x':2,'y':3,'z':4}\n",
    "    z_val = xyz_dict[label_key]\n",
    "    # Set up plot\n",
    "    fig = plt.figure(figsize=[12,12])\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot unmasked points\n",
    "    surrounding_no_mask = mask[0] != 0\n",
    "    unmasked_arr = np.array(lidar_data_processing.surrounding_grid(clean,surrounding_no_mask))\n",
    "    ax.scatter(unmasked_arr[:,0],unmasked_arr[:,1],unmasked_arr[:,z_val], marker='+')\n",
    "\n",
    "    # Plot masked, filled points\n",
    "    surrounding_mask = mask[0] == 0\n",
    "    filled_arr = np.array(lidar_data_processing.surrounding_grid(output,surrounding_mask))\n",
    "    ax.scatter(filled_arr[:,0],filled_arr[:,1],filled_arr[:,z_val], color='r', marker='o')\n",
    "\n",
    "    # Plot original, masked points\n",
    "    masked_arr = np.array(lidar_data_processing.surrounding_grid(clean,surrounding_mask))\n",
    "    ax.scatter(masked_arr[:,0],masked_arr[:,1],masked_arr[:,z_val], color='g', marker='o')\n",
    "\n",
    "    # Labels and such\n",
    "    ax.set_xlabel('Grid Across-Flight',fontsize=15)\n",
    "    ax.set_ylabel('Grid Along-Flight',fontsize=15)\n",
    "    ax.set_zlabel(label_key+' value',fontsize=15)\n",
    "\n",
    "    plt.show()\n",
    "plot_infill(inputs[im_idx],output[im_idx],mask[im_idx],'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_interp = lidar_data_processing.outer_interp_loop(inputs,mask_inputs,args.mask_pts_per_seq,2)\n",
    "plot_infill(inputs[im_idx],output_interp[im_idx],mask_inputs[im_idx],'z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
