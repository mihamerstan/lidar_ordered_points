{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data\n",
    "import models, utils\n",
    "\n",
    "import pandas as pd\n",
    "from laspy.file import File\n",
    "from pickle import dump, load\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as udata\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import lidar_data_processing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self):\n",
    "        self.data_path= 'data' # not used\n",
    "        self.dataset= 'masked_pwc' # move lidar into datasets\n",
    "        self.batch_size= 32\n",
    "        self.model= 'lidar_unet2d'\n",
    "        self.in_channels = 7\n",
    "        self.lr= 0.005\n",
    "        self.weight_decay = 0.005\n",
    "        self.num_epochs= 20\n",
    "        self.n_data = 1 # not used\n",
    "        self.min_sep = 5 # not used\n",
    "        self.num_scan_lines = 300\n",
    "        self.seq_len = 64\n",
    "        self.scan_line_gap_break = 7000 # threshold over which scan_gap indicates a new scan line\n",
    "        self.min_pt_count = 1700 # in a scan line, otherwise line not used\n",
    "        self.max_pt_count = 2000 # in a scan line, otherwise line not used\n",
    "        self.mask_pts_per_seq = 5\n",
    "        self.mask_consecutive = True\n",
    "        # points in between scan lines\n",
    "        self.stride_inline = 5\n",
    "        self.stride_across_lines = 3\n",
    "        self.valid_interval= 1 \n",
    "        self.save_interval= 1\n",
    "        self.seed = 0\n",
    "        self.output_dir= 'lidar_experiments/2d'\n",
    "        self.experiment= None\n",
    "        self.resume_training= False\n",
    "        self.restore_file= None\n",
    "        self.no_save= False\n",
    "        self.step_checkpoints= False\n",
    "        self.no_log= False\n",
    "        self.log_interval= 100\n",
    "        self.no_visual= False\n",
    "        self.visual_interval= 100\n",
    "        self.no_progress= False\n",
    "        self.draft= False\n",
    "        self.dry_run= False\n",
    "        self.bias= False \n",
    "#         self.in_channels= 1 # maybe 6?\n",
    "        self.test_num = 0\n",
    "        # UNET\n",
    "        self.residual = False\n",
    "        self.wtd_loss = True\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu or cpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# args = utils.setup_experiment(args)\n",
    "# utils.init_logging(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pts files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads as a list of numpy arrays\n",
    "scan_line_tensor = torch.load('../lidar_data/'+'scan_line_tensor.pts')\n",
    "train_idx_list = torch.load('../lidar_data/'+'train_idx_list.pts')\n",
    "valid_idx_list = torch.load('../lidar_data/'+'valid_idx_list.pts')\n",
    "sc = torch.load('../lidar_data/'+'sc.pts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask(sample,mask_pts_per_seq,consecutive=True):\n",
    "    # Given a 3-D tensor of all ones, returns a mask_tensor of same shape \n",
    "    # with random masking determined by mask_pts_per_seq\n",
    "    mask_tensor = torch.ones(sample.shape)\n",
    "    seq_len = mask_tensor.shape[0]\n",
    "    \n",
    "    if consecutive:\n",
    "        # Creates a square of missing points\n",
    "        first_mask_row = int(np.random.choice(np.arange(8,seq_len-8-mask_pts_per_seq),1))\n",
    "        first_mask_col = int(np.random.choice(np.arange(8,seq_len-8-mask_pts_per_seq),1))\n",
    "        \n",
    "        mask_tensor[first_mask_row:first_mask_row+mask_pts_per_seq,first_mask_col:first_mask_col+mask_pts_per_seq,:] = 0\n",
    "            \n",
    "    else:\n",
    "        # TO DO: Random points throughout the patch\n",
    "        for i in range(sample.shape[0]):\n",
    "            m[i,:] = np.random.choice(np.arange(8,seq_len-8),mask_pts_per_seq,replace=False)\n",
    "\n",
    "    return mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader class\n",
    "class LidarLstmDataset(udata.Dataset):\n",
    "    def __init__(self, scan_line_tensor, idx_list, seq_len = 64, mask_pts_per_seq = 5, consecutive = True):\n",
    "        super(LidarLstmDataset, self).__init__()\n",
    "        self.scan_line_tensor = scan_line_tensor\n",
    "        self.idx_list = idx_list\n",
    "        self.seq_len = seq_len\n",
    "        self.mask_pts_per_seq = mask_pts_per_seq\n",
    "        self.consecutive = consecutive\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        row = self.idx_list[index][0]\n",
    "        col = self.idx_list[index][1]\n",
    "        clean = self.scan_line_tensor[row:row+self.seq_len,col:col+self.seq_len,:]\n",
    "        mask = add_mask(clean,self.mask_pts_per_seq,self.consecutive)\n",
    "        return clean.permute(2,0,1), mask.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 64\n",
    "mask_pts_per_seq = 5\n",
    "train_dataset = LidarLstmDataset(scan_line_tensor,train_idx_list,seq_len, mask_pts_per_seq)\n",
    "valid_dataset = LidarLstmDataset(scan_line_tensor,valid_idx_list,seq_len, mask_pts_per_seq)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, num_workers=4, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c,m = next(iter(train_loader))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_MSELoss(pred,true,sc,mask_pts_per_seq=args.mask_pts_per_seq):\n",
    "    '''weighted_MSELoss reconverts MSE loss back to the original scale of x,y,z.\n",
    "    Rationale is because xyz have such different ranges, we don't want to ignore the ones with largest scale.\n",
    "    Assumes that x,y,z are the first 3 features in sc scaler'''\n",
    "    \n",
    "    ranges = torch.Tensor(sc.data_max_[:3]-sc.data_min_[:3])\n",
    "    raw_loss = torch.zeros(3,dtype=float)\n",
    "    for i in range(3):\n",
    "        raw_loss[i] = F.mse_loss(pred[:,i,:,:], true[:,i,:,:], reduction=\"sum\") \n",
    "    return (ranges**2 * raw_loss).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(444.5171, dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 2\n",
    "out = lidar_data_processing.outer_interp_loop(c,m,mask_pts_per_seq,n)\n",
    "weighted_MSELoss(out,c,sc,mask_pts_per_seq) / (c.shape[0]*mask_pts_per_seq**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
